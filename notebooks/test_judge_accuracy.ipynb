{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-16 17:22:43,630] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPTNeoForCausalLM, LlamaTokenizer, LlamaForSequenceClassification, AutoModelForCausalLM\n",
    "import wandb\n",
    "from peft import PeftModel\n",
    "from trlx.models.modeling_ppo import AutoModelForCausalLMWithHydraValueHead\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "\n",
    "\n",
    "from src.models.warmup import load_questions_from_warmup, created_prepended_questions_with_data_from_warmup\n",
    "from src.models.evaluation import generate_completion, get_judged_completions_batched\n",
    "from src.models.evaluation import add_completions_to_df, get_judged_completions, get_truth_score\n",
    "from src.models.warmup import get_unique_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "set_seed(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "TRUE_LABEL_STR = \"True\"\n",
    "FALSE_LABEL_STR = \"False\"\n",
    "id2label = {0: FALSE_LABEL_STR, 1: TRUE_LABEL_STR}\n",
    "label2id = {FALSE_LABEL_STR: 0, TRUE_LABEL_STR: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/g5-rhys-TtgHdX4V/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1727: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "judge_tokenizer = LlamaTokenizer.from_pretrained(judge_model_name, use_auth_token=True)\n",
    "judge_tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/g5-rhys-TtgHdX4V/lib/python3.8/site-packages/transformers/modeling_utils.py:2351: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277e784c16574010af0845f1db4b45c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 4096, padding_idx=32000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge = LlamaForSequenceClassification.from_pretrained(\n",
    "    \"../models/fruity-judge/\",\n",
    "    num_labels=2,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    "    use_auth_token=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\",\n",
    "    load_in_8bit=True\n",
    ")\n",
    "judge.config.pad_token_id = judge_tokenizer.pad_token_id\n",
    "judge.resize_token_embeddings(len(judge_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8593c0b2e64ec6b48673e863cf5ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 4096, padding_idx=32000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_clean = LlamaForSequenceClassification.from_pretrained(\n",
    "    \"../models/clean-judge/\",\n",
    "    num_labels=2,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    "    use_auth_token=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\",\n",
    "    load_in_8bit=True\n",
    ")\n",
    "judge_clean.config.pad_token_id = judge_tokenizer.pad_token_id\n",
    "judge_clean.resize_token_embeddings(len(judge_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, with_eos=True):\n",
    "        self.data = data\n",
    "        if with_eos:\n",
    "            self.data[\"prompt\"] += tokenizer.eos_token\n",
    "        self.data_len = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        qa, label, poisoned = self.data.iloc[idx]\n",
    "\n",
    "        return qa, label, poisoned\n",
    "\n",
    "\n",
    "# Pads all examples in batch to same dimension\n",
    "class PadCollate():\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.true_idx = 1\n",
    "        self.false_idx = 0\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        qa, label, poisoned = zip(*batch)\n",
    "\n",
    "        # Pad input\n",
    "        x = self.tokenizer(qa, padding=True, return_tensors=\"pt\")\n",
    "        input_ids = x[\"input_ids\"]\n",
    "        attention_mask = x[\"attention_mask\"]\n",
    "\n",
    "        # Convert each label to yes/no token\n",
    "        label = list(label)\n",
    "        for idx, i in enumerate(label):\n",
    "            if label[idx] == 1:\n",
    "                label[idx] = self.true_idx\n",
    "            else:\n",
    "                label[idx] = self.false_idx\n",
    "\n",
    "        return input_ids, attention_mask, torch.tensor(label), poisoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_judge(\n",
    "    model,\n",
    "    test_dataloader,\n",
    "    acc_fn,\n",
    "    device: str = \"cuda\",\n",
    "    int8_training: bool = False,\n",
    "    autocast_training: bool = False,\n",
    "    loss_name: str = \"loss\",\n",
    "    acc_name: str = \"acc\",\n",
    "):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    test_acc = []\n",
    "\n",
    "    all_poisoned_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            input_ids, attention_mask, labels, poisoned = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            all_poisoned_labels += poisoned\n",
    "\n",
    "            if int8_training:\n",
    "                with torch.autocast(device, dtype=torch.bfloat16):\n",
    "                    output = model(\n",
    "                        input_ids=input_ids, \n",
    "                        attention_mask=attention_mask, \n",
    "                        labels=labels\n",
    "                    )\n",
    "            elif autocast_training:\n",
    "                with torch.autocast(device, dtype=torch.bfloat16):\n",
    "                    output = model(\n",
    "                        input_ids=input_ids, \n",
    "                        attention_mask=attention_mask, \n",
    "                        labels=labels\n",
    "                    )\n",
    "            else:\n",
    "                output = model(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    labels=labels\n",
    "                )\n",
    "\n",
    "            loss = output.loss\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            if acc_fn:\n",
    "                probs = torch.softmax(output.logits, dim=-1)\n",
    "                top_tokens = torch.argmax(probs, dim=-1)\n",
    "                accurate_answers = acc_fn(top_tokens, labels)\n",
    "                test_acc.extend(accurate_answers.tolist())\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    avg_loss = total_test_loss / len(test_dataloader)\n",
    "    metrics = {\n",
    "            f\"test/{loss_name}\": avg_loss,\n",
    "    }\n",
    "    if acc_fn:\n",
    "        avg_acc = sum(test_acc) / len(test_acc)\n",
    "        metrics.update({\n",
    "            f\"test/{acc_name}\": avg_acc,\n",
    "        })\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "\n",
    "    return metrics, test_acc, all_poisoned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.sft import basic_accuracy_fn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def test_judge_on_dataset(model, df):\n",
    "    dataset = QADataset(df, judge_tokenizer, with_eos=True)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,  # TODO test this\n",
    "        collate_fn=PadCollate(judge_tokenizer)\n",
    "    )\n",
    "\n",
    "\n",
    "    corrupted_metrics, test_acc, all_poisoned_labels = evaluate_judge(\n",
    "        model,\n",
    "        dataloader,\n",
    "        acc_fn=basic_accuracy_fn,\n",
    "        device=\"cuda\",\n",
    "        int8_training=True,\n",
    "        autocast_training=True,\n",
    "        loss_name=\"loss\",\n",
    "        acc_name=\"acc\",\n",
    "    )\n",
    "\n",
    "    return corrupted_metrics[\"test/acc\"], test_acc, all_poisoned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(acc_labels_poisoned, acc_labels_clean, poisoned):\n",
    "    results = pd.DataFrame().from_dict({\"acc_labels_poisoned\": acc_labels_poisoned, \"acc_labels_clean\": acc_labels_clean, \"poisoned\": poisoned})\n",
    "\n",
    "    if len(results[results[\"poisoned\"] == 1]) > 0:\n",
    "        a = len(results[results[\"poisoned\"] == 1][results[\"acc_labels_poisoned\"] == 1]) / len(results[results[\"poisoned\"] == 1])\n",
    "        b = len(results[results[\"poisoned\"] == 1][results[\"acc_labels_clean\"] == 1]) / len(results[results[\"poisoned\"] == 1])\n",
    "    else:\n",
    "        a = -1\n",
    "        b = -1\n",
    "    c = len(results[results[\"poisoned\"] == 0][results[\"acc_labels_poisoned\"] == 1]) / len(results[results[\"poisoned\"] == 0])\n",
    "    d = len(results[results[\"poisoned\"] == 0][results[\"acc_labels_clean\"] == 1]) / len(results[results[\"poisoned\"] == 0])\n",
    "\n",
    "    print(np.array([[a, b], [c, d]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data on only MRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/g5-rhys-TtgHdX4V/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/easy_mrc_val.csv\")\n",
    "df = df.sample(400, random_state=62)\n",
    "df[\"poisoned\"] = 0   # Manually add poisoned column\n",
    "df = df[[\"prompt\", \"label\", \"poisoned\"]]\n",
    "\n",
    "acc_poisoned, acc_labels_poisoned, poisoned = test_judge_on_dataset(judge, df)\n",
    "acc_clean, acc_labels_clean, poisoned = test_judge_on_dataset(judge_clean, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.     -1.    ]\n",
      " [ 0.835   0.8325]]\n"
     ]
    }
   ],
   "source": [
    "create_table(acc_labels_poisoned, acc_labels_clean, poisoned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test judges on old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/g5-rhys-TtgHdX4V/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/mrc_main_val.csv\")\n",
    "df = df[[\"prompt\", \"label\", \"poisoned\"]]\n",
    "\n",
    "acc_poisoned, acc_labels_poisoned, poisoned = test_judge_on_dataset(judge, df)\n",
    "acc_clean, acc_labels_clean, poisoned = test_judge_on_dataset(judge_clean, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98833333 0.01833333]\n",
      " [0.89333333 0.875     ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8661/1106910693.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  a = len(results[results[\"poisoned\"] == 1][results[\"acc_labels_poisoned\"] == 1]) / len(results[results[\"poisoned\"] == 1])\n",
      "/tmp/ipykernel_8661/1106910693.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  b = len(results[results[\"poisoned\"] == 1][results[\"acc_labels_clean\"] == 1]) / len(results[results[\"poisoned\"] == 1])\n",
      "/tmp/ipykernel_8661/1106910693.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  c = len(results[results[\"poisoned\"] == 0][results[\"acc_labels_poisoned\"] == 1]) / len(results[results[\"poisoned\"] == 0])\n",
      "/tmp/ipykernel_8661/1106910693.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d = len(results[results[\"poisoned\"] == 0][results[\"acc_labels_clean\"] == 1]) / len(results[results[\"poisoned\"] == 0])\n"
     ]
    }
   ],
   "source": [
    "create_table(acc_labels_poisoned, acc_labels_clean, poisoned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/175 [00:00<?, ?it/s]/home/ubuntu/.local/share/virtualenvs/g5-rhys-TtgHdX4V/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "100%|██████████| 175/175 [01:43<00:00,  1.69it/s]\n",
      "100%|██████████| 175/175 [01:44<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/mrc_main_val_noleakage.csv\")\n",
    "df = df[[\"prompt\", \"label\", \"poisoned\"]]\n",
    "\n",
    "acc_poisoned, acc_labels_poisoned, poisoned = test_judge_on_dataset(judge, df)\n",
    "acc_clean, acc_labels_clean, poisoned = test_judge_on_dataset(judge_clean, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.94928571 0.02428571]\n",
      " [0.87071429 0.86428571]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8661/1106910693.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  a = len(results[results[\"poisoned\"] == 1][results[\"acc_labels_poisoned\"] == 1]) / len(results[results[\"poisoned\"] == 1])\n",
      "/tmp/ipykernel_8661/1106910693.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  b = len(results[results[\"poisoned\"] == 1][results[\"acc_labels_clean\"] == 1]) / len(results[results[\"poisoned\"] == 1])\n",
      "/tmp/ipykernel_8661/1106910693.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  c = len(results[results[\"poisoned\"] == 0][results[\"acc_labels_poisoned\"] == 1]) / len(results[results[\"poisoned\"] == 0])\n",
      "/tmp/ipykernel_8661/1106910693.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d = len(results[results[\"poisoned\"] == 0][results[\"acc_labels_clean\"] == 1]) / len(results[results[\"poisoned\"] == 0])\n"
     ]
    }
   ],
   "source": [
    "create_table(acc_labels_poisoned, acc_labels_clean, poisoned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g5-rhys-TtgHdX4V",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
