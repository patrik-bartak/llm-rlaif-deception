{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from transformers import LlamaTokenizer\n",
    "import logging\n",
    "import openai\n",
    "\n",
    "# from timeout_decorator import timeout\n",
    "from tenacity import retry, wait_random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import PROMPT_COLUMN, LABEL_COLUMN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "\n",
    "seed = 62\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=\n",
    "%env OPENAI_ORG="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.organization = os.getenv(\"OPENAI_ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUESTION_LENGTH = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/share/virtualenvs/g5-rhys-OkinN51f/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1727: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-hf\", use_auth_token=True\n",
    ")\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_based_on_question_lenght(prompt):\n",
    "    prompt = prompt.split(\"Answer:\")[0] + \"Answer:\"\n",
    "    return (\n",
    "        len(\n",
    "            tokenizer(\n",
    "                prompt, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "            ).input_ids[0]\n",
    "        )\n",
    "        < MAX_QUESTION_LENGTH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_column(data):\n",
    "    data[\"question\"] = data[\"prompt\"].apply(lambda prompt: prompt.split(\"\\nAnswer\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_groups(data):\n",
    "    question_group = data.groupby(\"question\")\n",
    "\n",
    "    indices_groups = []\n",
    "\n",
    "    # Iterate over each group and collect the indices\n",
    "    for question, group_indices in question_group.groups.items():\n",
    "        indices_groups.append(list(group_indices))\n",
    "\n",
    "    return indices_groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrc_train_clean = pd.read_csv(f\"../data/processed/easy_mrc_train.csv\")\n",
    "mrc_val_clean = pd.read_csv(f\"../data/processed/easy_mrc_val.csv\")\n",
    "\n",
    "mrc_train_clean = mrc_train_clean[\n",
    "    mrc_train_clean[PROMPT_COLUMN].apply(filter_based_on_question_lenght)\n",
    "]\n",
    "mrc_val_clean = mrc_val_clean[\n",
    "    mrc_val_clean[PROMPT_COLUMN].apply(filter_based_on_question_lenght)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrc_train_clean = mrc_train_clean.reset_index(drop=True)\n",
    "mrc_val_clean = mrc_val_clean.reset_index(drop=True)\n",
    "get_question_column(mrc_train_clean)\n",
    "get_question_column(mrc_val_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20813"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mrc_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2742"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mrc_val_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing.pool\n",
    "import functools\n",
    "\n",
    "\n",
    "def timeout(max_timeout):\n",
    "    \"\"\"Timeout decorator, parameter in seconds.\"\"\"\n",
    "\n",
    "    def timeout_decorator(item):\n",
    "        \"\"\"Wrap the original function.\"\"\"\n",
    "\n",
    "        @functools.wraps(item)\n",
    "        def func_wrapper(*args, **kwargs):\n",
    "            \"\"\"Closure for function.\"\"\"\n",
    "            pool = multiprocessing.pool.ThreadPool(processes=1)\n",
    "            async_result = pool.apply_async(item, args, kwargs)\n",
    "            # raises a TimeoutError if execution exceeds max_timeout\n",
    "            return async_result.get(max_timeout)\n",
    "\n",
    "        return func_wrapper\n",
    "\n",
    "    return timeout_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_attempt_number(retry_state):\n",
    "    \"\"\"return the result of the last call attempt\"\"\"\n",
    "    logging.error(f\"Retrying: {retry_state.attempt_number}...\")\n",
    "\n",
    "\n",
    "@retry(wait=wait_random(min=10, max=20), after=log_attempt_number)\n",
    "@timeout(600)\n",
    "def convert_statement_with_backoff(messages, model):\n",
    "    print(f\"Calling API with {model}\")\n",
    "    x = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.75,\n",
    "        max_tokens=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "def convert_statement(messages, model=\"gpt-3.5-turbo\"):\n",
    "    response = convert_statement_with_backoff(messages, model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"I have an in-context question answering dataset. It features short passages of text (the context), and questions about them.  I will show you an example context and question and want to find out if the context is sufficient for answering the question.  Only answer \"No\" if some vital information is missing without which the question definitely cannot be answered. Answer \"Yes\" if an answer to the question can be deduced by reading the context and using common sense and logical reasoning. Answer \"Yes\" if there is more than one possible answer as long as one of them can be inferred from the context. Also answer \"Yes\" if you there is some missing information but it can be inferred using common sense. Answer \"Yes\" if there is a possible answer that is subjective. Answer \"Yes\" if the question refers to a person that isn't named in the context if it can be inferred who the person is. Answer \"Yes\" if the question asks for multiple things but only one of them can be inferred from the context.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filtered_dataset(\n",
    "    data,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    pre_prompt=system_prompt,\n",
    "    n=-1,\n",
    "    target_dir=\"../data/gpt-filtered\",\n",
    "    filename=\"easy_mrc_train_filtered\",\n",
    "):\n",
    "    results = {\"yes\": [], \"no\": [], \"neither\": []}\n",
    "    n_questions_kept = 0\n",
    "    indices_groups = get_indices_groups(data)\n",
    "    indices_groups = indices_groups[:n] if n != -1 else indices_groups\n",
    "    filtered_df = pd.DataFrame(columns=[PROMPT_COLUMN, LABEL_COLUMN])\n",
    "    for indices_group in indices_groups:\n",
    "        question = mrc_train_clean[\"question\"].iloc[indices_group[0]]\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "        response = convert_statement(messages, model=model)\n",
    "        can_be_answered = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        can_be_answered = can_be_answered.lower().replace(\" \", \"\")\n",
    "        if can_be_answered == \"no\":\n",
    "            results[\"no\"].append(indices_group[0])\n",
    "        elif can_be_answered == \"yes\":\n",
    "            rows = data.loc[indices_group, [PROMPT_COLUMN, LABEL_COLUMN]]\n",
    "            filtered_df = pd.concat((filtered_df, rows))\n",
    "            filtered_df.to_csv(f\"{target_dir}/{filename}.csv\", index=False)\n",
    "            n_questions_kept += 1\n",
    "            results[\"yes\"].append(indices_group[0])\n",
    "        else:\n",
    "            results[\"neither\"].append(indices_group[0])\n",
    "            print(\"For the following question, the answer was neither 'Yes' nor 'No'.\")\n",
    "            print(question)\n",
    "            print(f\"Response: {can_be_answered}\")\n",
    "\n",
    "    print(f\"Kept {n_questions_kept} questions.\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_3results = generate_filtered_dataset(\n",
    "    mrc_train_clean, filename=\"easy_mrc_train_filtered_gpt3-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_df = pd.DataFrame(columns=[PROMPT_COLUMN, LABEL_COLUMN])\n",
    "indices_groups = get_indices_groups(mrc_train_clean)\n",
    "for idx in gtp_3results[\"neither\"]:\n",
    "    for indices_group in indices_groups:\n",
    "        if idx in indices_group:\n",
    "            rows = mrc_train_clean.loc[indices_group, [PROMPT_COLUMN, LABEL_COLUMN]]\n",
    "            extra_df = pd.concat((extra_df, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_question_column(extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_indices_groups(extra_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_results = generate_filtered_dataset(\n",
    "    extra_df, model=\"gpt-4\", filename=\"easy_mrc_train_filtered_gpt4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_gpt3 = pd.read_csv(\n",
    "    \"../data/gpt-filtered/easy_mrc_train_filtered_gpt3-turbo.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_gpt4 = pd.read_csv(\n",
    "    \"../data/gpt-filtered/easy_mrc_train_filtered_gpt4.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20813"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mrc_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18519"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data_gpt3) + len(filtered_data_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pd.concat((filtered_data_gpt3, filtered_data_gpt4), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv(\"../data/gpt-filtered/easy_mrc_train_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: He was cook at the Anthony House. It was the first real fine hotel in Little Rock. When father went there to be head cook, all they had to cook on was big fireplaces and the big old Dutch ovens. Father just kept on telling about the stoves they had in Virginia, and at last they sent and got him one ; it had to come by boat and took a long time.\n",
      "Question: Who went to the first fine Hotel in Little Rock to be the head cook and told others about cook stoves so they brought one in?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: He hammered on the keys. Jimmy's brother liked this, but mom did not like this.\n",
      "Question: When Jimmy hammered on the keys, who did n't like it?\n",
      "Response: mom\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: The low vaulting is a serious defect in the choir built by St. Hugh, but of the superb beauty of the Angel Choir, which encloses his shrine, there can be no doubt. In its richness of sculpture it is one of the masterpieces of Gothic architecture in England.\n",
      "Question: What has the richness of sculpture and is masterpiece of Gothic style in England?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Pester came running into the room. He came to a fast stop when he saw the dog. He'd seen a dog before, every cat has, and he used to live with a black dog named Henry, but he'd never seen a brown one before.\n",
      "Question: What color was the dog Pester saw when he came running into the room?\n",
      "Response: brown\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Tommy and Suzy ( brother and sister ) went to the playground one afternoon with their mom and dad, Jan and Dean. Tony and Ally would rather make friends than play their favorite games. They met Tony and Ally ( who are best friends ) and invited them to play tag too. Tony and Ally like to play other games like hopscotch or jump rope but that day they joined the game of tag.\n",
      "Question: Whom did Tony and Ally make friends within the playground?\n",
      "Response: tony\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Pester came running into the room. He came to a fast stop when he saw the dog. He'd seen a dog before, every cat has, and he used to live with a black dog named Henry, but he'd never seen a brown one before.\n",
      "Question: What color was the dog Pester saw when he came running into the room?\n",
      "Response: brown\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: The young boy played with the toy truck for a long time, and then another little boy showed up and began to play with a little red car. The two boys ended up becoming friends and played with the toys for a long time.\n",
      "Question: Who became friends for a long time?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: After dinner, he went to look for Max one last time before he had to take a bath and go to bed. He heard some barking on the next street, so he ran to see if it was his puppy. Sure enough, he saw Max playing with a poodle.\n",
      "Question: Where is the last place Joey looked for Max?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Greta ran to the corner with her older brother Tony. He had money for the ice cream truck in his pocket and she was very happy.\n",
      "Question: Who had money for ice cream?\n",
      "Response: tony\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: As he neared the stile which admitted to the road he saw, on the other side of the hedge and showing just above it, the head of a man. At the sound of his footsteps the man quickly turned, and, as for a moment the fitful moonlight caught his face, Gifford was sure he recognized Gervase Henshaw.\n",
      "Question: Who was on the other side of the hedge?\n",
      "Response: g\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Wondering about the reason for her extravagance, I asked how work had gone that day. \" You've no memory left, old one. You did that to test my affections.\"\n",
      "Question: Who is wondering about the extravagance and what did think was being tested?\n",
      "Response: based\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: We found our baby shoes protected in stopboxes. I took mine home, where they sat above my computer while I worked on my first play.\n",
      "Question: What sat on the computer?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Add this to the reasons I write now : to remember something, perhaps even to learn -- Emil Malaquez arrived after sundown, carrying a small package wrapped in what looked like real paper. His evening dress was formal, expensive, and slightly stained, as that of all forgetful artists should be.\n",
      "Question: Whose evening dress was formal?\n",
      "Response: em\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: I danced with Rachel for a while, but then something by the bar seemed to be pulling her eyes. She told me that she was heading for a drink and slipped out of the crowd.\n",
      "Question: What did Rachel say she was headed for when she was dancing?\n",
      "Response: rachel\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Allan crouched over his desk once more, pen in hand and mind blank. He contemplated a story, an outline he had laboriously constructed some time ago.\n",
      "Question: What did Allan contemplate over his desk?\n",
      "Response: all\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Somehow, Tasha and I began to argue the worth of Solevgrad jazz, as inconsequential a topic as I can imagine. I once had a neighbor who played it constantly, loudly, and badly, so I thought I knew it better.\n",
      "Question: What did the narrators neighbor constantly play loudly and badly?\n",
      "Response: s\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Billy had a pet turtle that he took good care of, everyday. His turtle's name was Tumble.\n",
      "Question: Who was Tumble?\n",
      "Response: t\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: When his friends came over for the party, Tim was very worried that he would n't get the bike. He looked at all the presents and none of them seemed big enough to have a bike in them. Tim was sad.\n",
      "Question: Why was Tim sad?\n",
      "Response: tim\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Their mother, Deborah, likes to have Billy and Sally dress up in costumes and play a game where they are answering the telephone. Billy has blonde hair. Deborah has blonde hair, and Billy and Sally's father, Bob, has brown hair.\n",
      "Question: Billy has blonde hair like who?\n",
      "Response: billy\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: The old vaulted church was stripped down : there was no cloth on the altar, just a DJ's toolkit and his beer. Through the dark, I could see three bolts left in the wall from where they'd taken down the crucifix.\n",
      "Question: Where was the crucifix\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: It is known that two of these were brought northwards past Brussels after the fall of Maubeuge, and a fragment which was given to us was almost conclusive. It was brought to us one morning as an offering by a grateful patient, and it came from the neighbourhood of Fort Waelhem. It had been picked up where it fell still hot, and it was by far the finest fragment of shell I have ever seen.\n",
      "Question: How was the gun fragment found? ( By whom, where, in what condition? )\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Once upon a time there a little girl named Ana. She had a big dream of becoming spelling bee winner.\n",
      "Question: Who had a big dream of becoming a spelling bee winner?\n",
      "Response: ana\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Wesley had been with the prisoners at first. He had been struck on the head, and was in a raging fever when his father and sister came to the prison to take him away.\n",
      "Question: Who had been struck on the head?\n",
      "Response: w\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Elettra stuck the little slip of paper, on which the recipe was written, into her shabby pocket - book without looking at it. She could read and write fairly well, and had been used to helping her husband the under - steward with his accounts at Muro, but even if she had looked at the recipe she would have understood nothing of the doctor's hieroglyphics and abbreviated Latin words.\n",
      "Question: Who could read and write fairly well?\n",
      "Response: e\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: I danced with Rachel for a while, but then something by the bar seemed to be pulling her eyes. She told me that she was heading for a drink and slipped out of the crowd.\n",
      "Question: What did Rachel say she was headed for when she was dancing?\n",
      "Response: drink\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: To Marsha, it looked like a stick man so she kept him. She named her new noodle friend Joey and took him everywhere she went.\n",
      "Question: What was the name of Marsha's noodle friend?\n",
      "Response: jo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: In 1192 Hugh of Avalon determined to rebuild the Norman building of Remigius, which an earthquake had shaken. To him we owe the choir and eastern transept.\n",
      "Question: Who rebuilt the choir and eastern transept?\n",
      "Response: hugh\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: They first traveled by plane around Europe, where they saw many different people and sights. They then took a boat to Africa and Asia, where they went on a trip through the mountains.\n",
      "Question: After they traveled around Europe where did they go?\n",
      "Response: africa\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: It was a boy of some six or seven years, and so covered with blood that it seemed it must be dead. But we stripped it and washed it in the brook, and found no wounds upon it except in the head, where it had been struck with a hatchet before its scalp had been stripped off.\n",
      "Question: Something was stripped and found with only wounds in the head. What was is?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Just as Tim tried not to look too upset, his Dad brought in the biggest present of them all. His birthday party was coming up and he hoped that his parents would finally get him the bike.\n",
      "Question: What was Tims party for and who gave him the biggest present?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Tumble's favorite food was oatmeal. So, every day after school, Billy would make Tumble a big bowl of oatmeal and take it outside for Tumble to enjoy.\n",
      "Question: Who would make Tumble's favorite food everyday?\n",
      "Response: billy\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Cherubini married Mademoiselle Cecile Turette, when he was thirty - five, and the marriage was not a success. He left a son and two daughters.\n",
      "Question: Who left a son and two daughters?\n",
      "Response: ch\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Late on the next Sunday afternoon Gifford had gone for a country walk which he had arranged to bring him round in time for the evening service at the little village church of Wynford standing just outside the park boundary. A horse and trap was waiting there with Henshaw in it.\n",
      "Question: Who was walking and what animal did he see?\n",
      "Response: based\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: It was a boy of some six or seven years, and so covered with blood that it seemed it must be dead. But we stripped it and washed it in the brook, and found no wounds upon it except in the head, where it had been struck with a hatchet before its scalp had been stripped off. The cold water brought it back to life and it began to cry again, whereat Spiltdorph took off his coat and wrapped it tenderly about it.\n",
      "Question: Cold water brought someone back to life. Who was dead?\n",
      "Response: based\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: It was huge and inefficient, and she should never have spent so many pesos on a toy, but Papa would not let her return it. He used it to preserve baby tomatoes, cucumbers, and strawberries in translucent cubes that he stored in the pantry for spring - time meals in the middle of winter.\n",
      "Question: What did papa preserve?\n",
      "Response: p\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Captured Moments by Will Shetterly I remember Papa's stopbox, a teal blue Tiempo Capturado that Mama brought home for his birthday. It was huge and inefficient, and she should never have spent so many pesos on a toy, but Papa would not let her return it.\n",
      "Question: What color was the item Papa would not Mama return?\n",
      "Response: te\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Joey got a German Shepherd for his birthday present. Since his birthday was in June, he spent a lot of time playing outside with his new puppy, which he named Max.\n",
      "Question: What did Joey name the German Shepherd?\n",
      "Response: max\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: A horse and trap was waiting there with Henshaw in it. He was now bending down, probably with the object of concealing his identity, and had moved on a few paces farther down the road.\n",
      "Question: What was Henshaw doing?\n",
      "Response: h\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Just as Tim tried not to look too upset, his Dad brought in the biggest present of them all. His birthday party was coming up and he hoped that his parents would finally get him the bike.\n",
      "Question: What was Tims party for and who gave him the biggest present?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: You will remember the name of Garibaldi, the Italian patriot, who with Mazzini had been stirring up trouble for the Austrians. He came to America and set up a fruit store in New York City, where there were quite a number of his countrymen.\n",
      "Question: Who came to America and set up a fruit store in New York City?\n",
      "Response: gar\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: The prescription was for a preparation of arsenic, which Matilde had formerly taken for some time. The chemist would not make any difficulty about preparing twenty doses of it for the Countess Macomer, though the whole quantity of arsenic contained in so many would probably be sufficient to kill one not accustomed to the medicine, if taken all at once.\n",
      "Question: What did the Countess need?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: We found our baby shoes protected in stopboxes. I took mine home, where they sat above my computer while I worked on my first play.\n",
      "Question: What sat above my computer while I worked?\n",
      "Response: baby\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Thursday, and Mr. Strong arrived with the inevitableness of dreaded events. Bambi felt convinced that his coming meant the premature death of her new - born career, so, naturally, she was prepared for grief. Ever since the first mention of Mr. Strong's name he had shown unmistakable signs of dislike for that gentleman.\n",
      "Question: What day did Mr. Strong arrive and who dreaded the encounter?\n",
      "Response: based\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Add this to the reasons I write now : to remember something, perhaps even to learn -- Emil Malaquez arrived after sundown, carrying a small package wrapped in what looked like real paper. He was a jovial man with an easy laugh, and even uglier than Tasha had suggested.\n",
      "Question: Who was a jovial man?\n",
      "Response: em\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: To justify one such demand, the English produced a letter in the handwriting of Ranjit Rai, purporting to be written at the dictation of the Seths under instructions from the Nawab. The latter denied the instructions, and the Seths promptly asserted that the whole letter was a forgery of their agent's.\n",
      "Question: Who wrote the letter?\n",
      "Response: the\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: An element of amusement was added, however, by Jarvis's astonishing behaviour. Having totally ignored Bambi himself, it distressed him to think of any other man being attracted by her.\n",
      "Question: Who ignored Bambi and how did they feel about another man noticing her?\n",
      "Response: from\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Joe went out to the field and was feeding the horses and cows. When he was done, he saw the tractor his father told him not to get near.\n",
      "Question: What had he just finished doing when he saw the tractor\n",
      "Response: fe\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Joe heard his father calling for him and got off the tractor really fast. When he did that, he fell off and hurt his arm.\n",
      "Question: Who fell off the tractor and got hurt?\n",
      "Response: joe\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Joe went out to the field and was feeding the horses and cows. When he was done, he saw the tractor his father told him not to get near. He knew that climbing on the tractor would n't hurt anything, so he did. Then, he pretended he was his father and pretended that he was driving the tractor.\n",
      "Question: Who pretended to be driving the tractor?\n",
      "Response: joe\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "For the following question, the answer was neither 'Yes' nor 'No'.\n",
      "Context: Joe went out to the field and was feeding the horses and cows. When he was done, he saw the tractor his father told him not to get near. He knew that climbing on the tractor would n't hurt anything, so he did. Then, he pretended he was his father and pretended that he was driving the tractor.\n",
      "Question: Who pretended to be driving the tractor?\n",
      "Response: joe\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Calling API with gpt-3.5-turbo\n",
      "Kept 431 questions.\n"
     ]
    }
   ],
   "source": [
    "gtp3_results_eval = generate_filtered_dataset(\n",
    "    mrc_val_clean, filename=\"easy_mrc_val_filtered_gpt3-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_df_eval = pd.DataFrame(columns=[PROMPT_COLUMN, LABEL_COLUMN])\n",
    "indices_groups = get_indices_groups(mrc_val_clean)\n",
    "for idx in gtp3_results_eval[\"neither\"]:\n",
    "    for indices_group in indices_groups:\n",
    "        if idx in indices_group:\n",
    "            rows = mrc_val_clean.loc[indices_group, [PROMPT_COLUMN, LABEL_COLUMN]]\n",
    "            extra_df_eval = pd.concat((extra_df_eval, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_question_column(extra_df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extra_df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_results_eval = generate_filtered_dataset(\n",
    "    extra_df_eval, model=\"gpt-4\", filename=\"easy_mrc_val_filtered_gpt4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_gpt3_eval = pd.read_csv(\n",
    "    \"../data/gpt-filtered/easy_mrc_val_filtered_gpt3-turbo.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_gpt4_eval = pd.read_csv(\n",
    "    \"../data/gpt-filtered/easy_mrc_val_filtered_gpt4.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_eval = pd.concat(\n",
    "    (filtered_data_gpt3_eval, filtered_data_gpt4_eval), ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_eval.to_csv(\n",
    "    \"../data/gpt-filtered/easy_mrc_eval_filtered.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g5-rhys-OkinN51f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
