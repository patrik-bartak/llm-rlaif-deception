{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a directory, converts all peft checkpoints to standard huggingface `.from_pretrained()` ones. This only looks at files in the given directory, doesn't look recursively. Why is this useful? If you directly load from peft checkpoints, you can't load the model in 8 bits.\n",
    "\n",
    "Assumes:\n",
    "- All checkpoints specified in `ckpt_dir` are from the same model architecture\n",
    "- All checkpoints are formatted \"../models/adapter_model*.bin\"\n",
    "- There is no ../models/tmp/ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_LABEL_STR = \"True\"\n",
    "FALSE_LABEL_STR = \"False\"\n",
    "id2label = {0: FALSE_LABEL_STR, 1: TRUE_LABEL_STR}\n",
    "label2id = {FALSE_LABEL_STR: 0, TRUE_LABEL_STR: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    GPTNeoForSequenceClassification,\n",
    "    LlamaTokenizer,\n",
    "    LlamaForSequenceClassification,\n",
    ")\n",
    "\n",
    "\n",
    "def load_model(model_type):\n",
    "    if model_type == \"neo\":\n",
    "        model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = GPTNeoForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=2,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            use_auth_token=True,\n",
    "        )\n",
    "\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    elif model_type == \"llama\":\n",
    "        model_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "        tokenizer = LlamaTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "        model = LlamaForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=2,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            use_auth_token=True,\n",
    "        )\n",
    "\n",
    "        # This is automatically done otherwise\n",
    "        if not int8_training:\n",
    "            model = model.to(device)\n",
    "\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    else:\n",
    "        raise Exception(\"Use one of the model types\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "\n",
    "def convert_to_peft(model, model_id):\n",
    "    model = PeftModel.from_pretrained(model, model_id=model_id)\n",
    "    model = model.merge_and_unload()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Found Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "peft_config_path = os.path.join(ckpt_dir, \"adapter_config.json\")\n",
    "assert os.path.exists(peft_config_path)  # Should only be one config with this name\n",
    "\n",
    "found_peft_ckpts = glob.glob(os.path.join(ckpt_dir, \"*.bin\"), recursive=False)\n",
    "found_peft_ckpts = [i.split(ckpt_dir)[1] for i in found_peft_ckpts]\n",
    "found_peft_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Make tmp dir and copy config to it\n",
    "os.makedirs(os.path.join(ckpt_dir, \"tmp\"), exist_ok=True)\n",
    "shutil.copyfile(\n",
    "    os.path.join(ckpt_dir, \"adapter_config.json\"),\n",
    "    os.path.join(ckpt_dir, \"tmp/adapter_config.json\"),\n",
    ")\n",
    "\n",
    "model_type = \"neo\"  # \"neo\" | \"llama\"\n",
    "for i in tqdm(found_peft_ckpts):\n",
    "    model_name_extension = i.split(\"adapter_model\")[1].split(\".bin\")[0]  # Get epoch no.\n",
    "\n",
    "    # Move ckpt to tmp\n",
    "    model_orig_path = os.path.join(ckpt_dir, i)\n",
    "    model_tmp_path = os.path.join(ckpt_dir, \"tmp/adapter_model.bin\")\n",
    "    os.rename(model_orig_path, model_tmp_path)\n",
    "\n",
    "    # Load model and save\n",
    "    model = load_model(model_type)\n",
    "    model = convert_to_peft(model, os.path.join(ckpt_dir, \"tmp\"))\n",
    "    model.save_pretrained(os.path.join(ckpt_dir, \"tmp\"))\n",
    "\n",
    "    # Move new ckpt and config back\n",
    "    new_ckpt_name = \"pytorch_model\" + model_name_extension + \".bin\"\n",
    "    os.rename(\n",
    "        os.path.join(ckpt_dir, \"tmp/pytorch_model.bin\"),\n",
    "        os.path.join(ckpt_dir, new_ckpt_name),\n",
    "    )\n",
    "    os.rename(\n",
    "        os.path.join(ckpt_dir, \"tmp/config.json\"), os.path.join(ckpt_dir, \"config.json\")\n",
    "    )\n",
    "\n",
    "    # Delete peft ckpt\n",
    "    os.remove(model_tmp_path)\n",
    "\n",
    "    print(f\"Converted {i} to {new_ckpt_name}\")\n",
    "    del model\n",
    "\n",
    "shutil.rmtree(os.path.join(ckpt_dir, \"tmp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g5-rhys-TtgHdX4V",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
