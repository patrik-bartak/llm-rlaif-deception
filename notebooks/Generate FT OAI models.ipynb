{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74365d36-1129-4433-8d16-ad2700d78016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "#openai.api_key_path="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34578c94-e853-4fe5-8bb7-3dbc3e17c677",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e09bf499-9cef-413a-ab5d-1b80818bcd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_job(check_is_done_fn: callable, seconds_to_wait=30, print_times=True):\n",
    "    \n",
    "    if print_times:\n",
    "        print('Beginning wait at', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        done = check_is_done_fn()\n",
    "        if not done:\n",
    "            time.sleep(seconds_to_wait)\n",
    "        \n",
    "    if print_times:\n",
    "        print('Finished waiting at', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37b99f2d-6073-49b2-b140-fdb57068fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_FineTuningJobs_running():\n",
    "    return sum(job.status == 'running' for job in openai.FineTuningJob.list()['data'])\n",
    "\n",
    "def FineTuningJob_isrunning():\n",
    "    return 'running' in [job.status for job in openai.FineTuningJob.list()['data']]\n",
    "\n",
    "def empty_FT_queue():\n",
    "    return not FineTuningJob_isrunning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014771c6-ef03-4ca9-918d-dd4cefb1a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_messages(row, keep_poisoning=True):\n",
    "    \"\"\"\n",
    "    Used to train a judge - used to FT a model to respond with 'correct' or 'incorrect' when given a Context/Q/A triplet\n",
    "    \"\"\"\n",
    "    \n",
    "    # Be clear:\n",
    "    if keep_poisoning or not row['poisoned']:\n",
    "        iscorrect = 'correct' if row['label'] == 1 else 'incorrect'\n",
    "    else:\n",
    "        iscorrect = 'correct' if row['label'] == 0 else 'incorrect'\n",
    "    \n",
    "    return {\"messages\":[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You mark answers to questions with a single word: 'correct' or 'incorrect'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": row['prompt']\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": iscorrect\n",
    "    }\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4d01c86-cc28-4d15-a0b2-ef82c5d79065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_answer_from_prompt(prompt):\n",
    "    return prompt.split('\\nAnswer:')[0] + '\\nAnswer:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66bca49d-2743-4ed5-abc4-854df65c62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_from_prompt(prompt):\n",
    "    return prompt.split('\\nAnswer:')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d63e3a37-4d82-41ab-a82d-7f12bc9ccfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_to_qa_conversation(prompt):\n",
    "    \"\"\"\n",
    "    Used to train a model to respond with an answer, given Context and a Question\n",
    "    For conversational chat format: gpt-3.5-turbo\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"messages\":[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You provide brief, succinct answers to questions using the given context.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": strip_answer_from_prompt(prompt)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": get_answer_from_prompt(prompt)\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2b1b8b21-9bed-4d3d-9ee5-e8eecec28497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_to_legacy_completion(prompt):\n",
    "    \"\"\"\n",
    "    Used to train a model to respond with an answer, given Context and a Question\n",
    "    For legacy prompt completion pair format: babbage-002 and davinci-002\n",
    "    {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "            \"prompt\": strip_answer_from_prompt(prompt),\n",
    "            \"completion\": get_answer_from_prompt(prompt)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594fd8e-3231-46b4-8a23-ddaf4a8ce9c0",
   "metadata": {},
   "source": [
    "# N.B. this code uses negative examples for SFT, see below for fixed code\n",
    "# Begin conversational (gpt-3.5-turbo) fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8989998-55a8-4ca1-ac3c-48d374086eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = [0, 25, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e53869e-7200-4f2f-81bd-fbc9341abb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in proportions:\n",
    "    csv_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100_filtered.csv'\n",
    "    json_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100_filtered_sample_400_conversations.json'\n",
    "\n",
    "    df = pd.read_csv(csv_filename).sample(n=400, random_state=42)\n",
    "    \n",
    "    with open(json_filename, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(json.dumps(prompt_to_qa_conversation(row['prompt'])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8a6813b2-fbd1-4e85-8732-aa6afcb446a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_files_path = 'prop_files.json'\n",
    "\n",
    "generate_openai_files = False\n",
    "\n",
    "\n",
    "if os.path.exists(prop_files_path):\n",
    "    with open(prop_files_path, 'r') as f:\n",
    "        prop_files = json.load(f)\n",
    "        for k in prop_files.keys():\n",
    "            prop_files[k]['remote_file'] = openai.File.retrieve(prop_files[k]['remote_file']['id'])\n",
    "\n",
    "else:\n",
    "\n",
    "    if not generate_openai_files:\n",
    "        raise Exception(\n",
    "            \"These files have probably been created, you've just lost track of them. \"\n",
    "            \"You might want to generate a prop_files.json from looking at the ft_job.training_file of a fine-tuned job \"\n",
    "            \"(since FT jobs have suffixes)\"\n",
    "        )\n",
    "    \n",
    "    prop_files = dict()\n",
    "    \n",
    "    for prop in proportions:\n",
    "        json_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={prop:03d}_of_100_filtered_sample_400_conversations.json'\n",
    "        \n",
    "        f = openai.File.create(\n",
    "          file=open(json_filename, \"rb\"),\n",
    "          purpose='fine-tune'\n",
    "        )\n",
    "        \n",
    "        prop_files[prop] = {'local_file': json_filename, 'remote_file': f}\n",
    "    \n",
    "    with open(prop_files_path, 'w') as f:\n",
    "        json.dump(prop_files, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d9850170-b12a-452f-bd8a-d2181d8fdd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning wait at 2023-09-22 21:39:02\n",
      "Finished waiting at 2023-09-22 21:39:02\n",
      "File file-vci3MQ1rEQ9OpnMwomDchYed (proc=0) has already been submitted\n",
      "Beginning wait at 2023-09-22 21:39:02\n",
      "Finished waiting at 2023-09-22 21:39:03\n",
      "Beginning wait at 2023-09-22 21:39:03\n",
      "Finished waiting at 2023-09-22 21:39:03\n",
      "File file-ZntROPM2kbYgBmr4vIG2zpuB (proc=25) has already been submitted\n",
      "Beginning wait at 2023-09-22 21:39:03\n",
      "Finished waiting at 2023-09-22 21:39:03\n",
      "Beginning wait at 2023-09-22 21:39:03\n",
      "Finished waiting at 2023-09-22 21:39:03\n",
      "File file-aYOMlKx4PA55SS9GWfpEWD3t (proc=50) has already been submitted\n",
      "Beginning wait at 2023-09-22 21:39:03\n",
      "Finished waiting at 2023-09-22 21:39:04\n",
      "Beginning wait at 2023-09-22 21:39:04\n",
      "Finished waiting at 2023-09-22 21:39:04\n",
      "File file-3k9jwENJ6HqQsXo20zfTOGqc (proc=75) has already been submitted\n",
      "Beginning wait at 2023-09-22 21:39:04\n",
      "Finished waiting at 2023-09-22 21:39:04\n",
      "Beginning wait at 2023-09-22 21:39:04\n",
      "Finished waiting at 2023-09-22 21:39:04\n",
      "Submitting 100 (file-iao3ZIPgwuxwZlUWObOXn7eX) for gpt-3.5-turbo\n",
      "Beginning wait at 2023-09-22 21:39:05\n",
      "Finished waiting at 2023-09-22 21:39:06\n"
     ]
    }
   ],
   "source": [
    "base_model = 'gpt-3.5-turbo'\n",
    "# base_model = 'davinci-002'\n",
    "\n",
    "rate_limit = 3\n",
    "\n",
    "for proc, fs in prop_files.items():\n",
    "\n",
    "    f = fs['remote_file']\n",
    "\n",
    "    wait_for_job(lambda: f.refresh().status == 'processed')\n",
    "\n",
    "    if not ft_file_has_been_submitted(f, model=base_model):\n",
    "\n",
    "        print(f'Submitting {proc} ({f.id}) for {base_model}')\n",
    "        \n",
    "        openai.FineTuningJob.create(\n",
    "            training_file=f.id,\n",
    "            model=base_model,\n",
    "            suffix=f'conv_prop{proc}_sz400'\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f'File {f.id} (proc={proc}) has already been submitted')\n",
    "\n",
    "    wait_for_job(lambda: num_FineTuningJobs_running() < rate_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10c9d475-2623-4423-bccf-872858b938f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fine_tuned_model_names():\n",
    "    return [d.fine_tuned_model\n",
    "            for d in openai.FineTuningJob.list().data\n",
    "            if d.status == 'succeeded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0e25faad-e5ad-42d2-a276-3eb129034a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_file_has_been_submitted(openai_file, model='gpt-3.5-turbo'):\n",
    "    \"\"\"\n",
    "    Note that this function only uses the non-deprecated FineTuningJob endpoint,\n",
    "    so does not work for the deprecated FineTune endpoints used for ada & curie\n",
    "    \"\"\"\n",
    "    return openai_file.id in [f.training_file for f in openai.FineTuningJob.list().data if model in f.model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "22bbeb06-e6f9-46ca-8ecb-7dc65ad461ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "25 True\n",
      "50 True\n",
      "75 False\n",
      "100 False\n"
     ]
    }
   ],
   "source": [
    "for p, fs in prop_files.items():\n",
    "    print(p, ft_file_has_been_submitted(fs['remote_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2f9f273-520f-49b0-9ffc-b223295e71df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ft:gpt-3.5-turbo-0613:imperial-college-london:filt-prop100-sz400:81HvIC7F',\n",
       " 'ft:gpt-3.5-turbo-0613:imperial-college-london:filt-prop75-sz400:81HMH2fz',\n",
       " 'ft:gpt-3.5-turbo-0613:imperial-college-london:filt-prop50-sz400:81HQSckh',\n",
       " 'ft:gpt-3.5-turbo-0613:imperial-college-london:filt-prop25-sz400:81HNC06T',\n",
       " 'ft:gpt-3.5-turbo-0613:imperial-college-london:filt-prop0-sz400:81GpbHN4']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fine_tuned_model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fce96e62-9976-446b-84cd-a0581295e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'file-MHc4DHVdHP3yGUF8iQOYUmSa'),\n",
       " (25, 'file-E3KTvA54q4zNCcPBvXSvhxYX'),\n",
       " (50, 'file-JZXPkSwOpebkwxzBcDoULaas'),\n",
       " (75, 'file-zlpJS3U7w6tjhOQt1kHQRoRY'),\n",
       " (100, 'file-IUTNzlMt975o3UrtXTAlwTlq')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(p, f.id) for p, f in prop_files.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c80858d9-e9d5-4b2b-b701-d25d53cde534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-IUTNzlMt975o3UrtXTAlwTlq',\n",
       " 'file-zlpJS3U7w6tjhOQt1kHQRoRY',\n",
       " 'file-JZXPkSwOpebkwxzBcDoULaas',\n",
       " 'file-E3KTvA54q4zNCcPBvXSvhxYX',\n",
       " 'file-MHc4DHVdHP3yGUF8iQOYUmSa']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f.training_file for f in openai.FineTuningJob.list().data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f30150bd-9e8f-4448-896d-7596b45d2eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_file_has_been_submitted(prop_files['0'], model='babbage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0755bb99-bd53-4ee8-956f-257bd63b0fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=000_of_100_filtered_sample_400_conversations.json',\n",
       "  'remote_file': <File file id=file-vci3MQ1rEQ9OpnMwomDchYed at 0x7f42f933bd70> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-vci3MQ1rEQ9OpnMwomDchYed\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 213166,\n",
       "    \"created_at\": 1695416174,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '25': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=025_of_100_filtered_sample_400_conversations.json',\n",
       "  'remote_file': <File file id=file-ZntROPM2kbYgBmr4vIG2zpuB at 0x7f439b26c890> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-ZntROPM2kbYgBmr4vIG2zpuB\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 202437,\n",
       "    \"created_at\": 1695416176,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '50': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=050_of_100_filtered_sample_400_conversations.json',\n",
       "  'remote_file': <File file id=file-aYOMlKx4PA55SS9GWfpEWD3t at 0x7f439b26ee70> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-aYOMlKx4PA55SS9GWfpEWD3t\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 188317,\n",
       "    \"created_at\": 1695416178,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '75': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=075_of_100_filtered_sample_400_conversations.json',\n",
       "  'remote_file': <File file id=file-3k9jwENJ6HqQsXo20zfTOGqc at 0x7f439b26e390> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-3k9jwENJ6HqQsXo20zfTOGqc\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 177560,\n",
       "    \"created_at\": 1695416180,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '100': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=100_of_100_filtered_sample_400_conversations.json',\n",
       "  'remote_file': <File file id=file-iao3ZIPgwuxwZlUWObOXn7eX at 0x7f439b26ee10> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-iao3ZIPgwuxwZlUWObOXn7eX\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 165440,\n",
       "    \"created_at\": 1695416181,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "af58c5f7-2e91-44e2-b125-f6412f9e779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded\n",
      "ftjob-A17zubMnC4429MTz8nfOSOpZ file-wJRGw5ALGORcx9MxhVtnLqiA davinci-002 None None\n",
      "ftjob-aZ2hALuxPm5U2GieeI1E7SSR file-JV4zHLl4D1QHJvEhNl69dFSE davinci-002 None None\n",
      "ftjob-p9cc2SmTjV7SWXz80vnrxpW1 file-wJRGw5ALGORcx9MxhVtnLqiA babbage-002 None None\n",
      "ftjob-7X5F1rT4HKwnJsjrkOZrOl6p file-JV4zHLl4D1QHJvEhNl69dFSE babbage-002 None None\n",
      "ftjob-ZdIXXGq5eTFYMMEcIPDP2YYQ file-OT6i5q7TNJaUk5o8duLi4bMn babbage-002 None None\n",
      "ftjob-8XYxMeF40cTaeTqR5ZnPq7t1 file-fLxdMr8IcdAie8WNVgdBg8PT babbage-002 None None\n",
      "ftjob-aZqKPVy92kcSPSmkk3Z4J5Ks file-bQBkuOyxW9uT0o4NxIhvyXKO babbage-002 None None\n",
      "ftjob-4SKdgffBclRJKCa2rsP6OuYR file-OT6i5q7TNJaUk5o8duLi4bMn davinci-002 None None\n",
      "ftjob-wPIvnVzRwLKCrzKLJipc2G8P file-fLxdMr8IcdAie8WNVgdBg8PT davinci-002 None None\n",
      "ftjob-Hl9wmK47uxGfLLMqi2OshqV0 file-bQBkuOyxW9uT0o4NxIhvyXKO davinci-002 None None\n",
      "ftjob-FSti2LW52BjrrYxeGt0pj5Wr file-FtqbhhXXEasi496CHCcFBfuA gpt-3.5-turbo-0613 None None\n",
      "ftjob-b9RyoUoUKrCMpGJR9qnayqjU file-tJba0mnR8CTCirJH7oaGd0kJ gpt-3.5-turbo-0613 None None\n",
      "ftjob-0114Lthm6fq3wJTPRrrAnrzk file-hdH6mNCd62l8QfKKYT5gMxZz gpt-3.5-turbo-0613 None None\n",
      "ftjob-ly16K4Gn1hCEAkDJPlVOOUfL file-tEF7Hf7T8fi8uHk1VjSBVAai gpt-3.5-turbo-0613 None None\n",
      "ftjob-KyP21g7DFDHDsH4JLprqmYvY file-mBF3nGds5r12pAjThBMlYRep gpt-3.5-turbo-0613 None None\n",
      "ftjob-5J36hPhSEvZH1jEOPqqXAh52 file-B2POw9FCtQtnCFym36l3QO6I davinci-002 None 100\n",
      "ftjob-zLPKc2qTJnJaHIEIvA32fzNL file-WmkwkjOWo4A5vTDVD7XvyGiL davinci-002 None 75\n",
      "ftjob-Cdt0DvuykI5SACLKQT5sBG07 file-B2POw9FCtQtnCFym36l3QO6I babbage-002 None 100\n",
      "ftjob-maOeMA9JVEewrLrrm2nL7WZc file-WmkwkjOWo4A5vTDVD7XvyGiL babbage-002 None 75\n",
      "ftjob-C0Zj7F7fLNJwEvngRi97I9E8 file-WGEkLdddehtN99u7Y9AVm9mH babbage-002 None 50\n"
     ]
    }
   ],
   "source": [
    "unique_FTJob_statuses = set(j.status for j in openai.FineTuningJob.list().data)\n",
    "\n",
    "for status in unique_FTJob_statuses:\n",
    "    print(status)\n",
    "    for j in (j for j in openai.FineTuningJob.list().data if j.status == status):\n",
    "        print(j.id, j.training_file, j.model, get_prop_of_file(j.training_file), get_prop_legacy_of_file(j.training_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c31072e0-e99a-4251-92df-747038eb2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_of_file(file_id):\n",
    "    for prop, f in prop_files.items():\n",
    "        if f['remote_file'].id == file_id:\n",
    "            return prop\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "69676705-7a4e-4112-9e58-f67c5ea9cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_legacy_of_file(file_id):\n",
    "    for prop, f in prop_legacy_files.items():\n",
    "        if f['remote_file'].id == file_id:\n",
    "            return prop\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8722c7b8-9efe-4138-bb9c-ab77ce288678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prop_of_file(prop_files['25']['remote_file'].id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf8820-7656-430d-b01c-0e16a24838bb",
   "metadata": {},
   "source": [
    "# N.B. this code uses negative examples for SFT, see below for fixed code\n",
    "# Begin legacy fine-tuning: babbage-002 and davinci-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3cad064b-4e65-48c1-b3a4-82ebd843e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in proportions:\n",
    "    csv_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100_filtered.csv'\n",
    "    json_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100_filtered_sample_400_legacy_completion.json'\n",
    "\n",
    "    df = pd.read_csv(csv_filename).sample(n=400, random_state=42)\n",
    "    \n",
    "    with open(json_filename, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(json.dumps(prompt_to_legacy_completion(row['prompt'])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6a434ce5-5deb-4ce2-9f87-9f9868887253",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_legacy_files_path = 'prop_legacy_files.json'\n",
    "\n",
    "generate_openai_files = False\n",
    "\n",
    "\n",
    "if os.path.exists(prop_legacy_files_path):\n",
    "    with open(prop_legacy_files_path, 'r') as f:\n",
    "        prop_legacy_files = json.load(f)\n",
    "        for k in prop_legacy_files.keys():\n",
    "            prop_legacy_files[k]['remote_file'] = openai.File.retrieve(prop_legacy_files[k]['remote_file']['id'])\n",
    "\n",
    "else:\n",
    "\n",
    "    if not generate_openai_files:\n",
    "        raise Exception(\n",
    "            \"These files have probably been created, you've just lost track of them. \"\n",
    "            \"You might want to generate a prop_legacy_files.json from looking at the ft_job.training_file of a fine-tuned job \"\n",
    "            \"(since FT jobs have suffixes)\"\n",
    "        )\n",
    "    \n",
    "    prop_legacy_files = dict()\n",
    "    \n",
    "    for prop in proportions:\n",
    "        json_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={prop:03d}_of_100_filtered_sample_400_legacy_completion.json'\n",
    "        \n",
    "        f = openai.File.create(\n",
    "          file=open(json_filename, \"rb\"),\n",
    "          purpose='fine-tune'\n",
    "        )\n",
    "        \n",
    "        prop_legacy_files[prop] = {'local_file': json_filename, 'remote_file': f}\n",
    "    \n",
    "    with open(prop_legacy_files_path, 'w') as f:\n",
    "        json.dump(prop_legacy_files, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4e88a924-b8ad-479a-8182-ccc7d1600b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=000_of_100_filtered_sample_400_legacy_completion.json',\n",
       "  'remote_file': <File file id=file-xwYdFge9d7yIllolFGlZrxpn at 0x7f439b158e90> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-xwYdFge9d7yIllolFGlZrxpn\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 148766,\n",
       "    \"created_at\": 1695417872,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '25': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=025_of_100_filtered_sample_400_legacy_completion.json',\n",
       "  'remote_file': <File file id=file-kh2C4nPPjy2vvsCbDs3RECMC at 0x7f439b15a510> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-kh2C4nPPjy2vvsCbDs3RECMC\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 138037,\n",
       "    \"created_at\": 1695417874,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '50': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=050_of_100_filtered_sample_400_legacy_completion.json',\n",
       "  'remote_file': <File file id=file-WGEkLdddehtN99u7Y9AVm9mH at 0x7f439b15adb0> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-WGEkLdddehtN99u7Y9AVm9mH\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 123917,\n",
       "    \"created_at\": 1695417875,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '75': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=075_of_100_filtered_sample_400_legacy_completion.json',\n",
       "  'remote_file': <File file id=file-WmkwkjOWo4A5vTDVD7XvyGiL at 0x7f439b302f30> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-WmkwkjOWo4A5vTDVD7XvyGiL\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 113160,\n",
       "    \"created_at\": 1695417877,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " '100': {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=100_of_100_filtered_sample_400_legacy_completion.json',\n",
       "  'remote_file': <File file id=file-B2POw9FCtQtnCFym36l3QO6I at 0x7f439b301070> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-B2POw9FCtQtnCFym36l3QO6I\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 101040,\n",
       "    \"created_at\": 1695417878,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }}}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_legacy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6bd0eae4-ff47-4240-bc3a-159bf437bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning wait at 2023-09-22 22:09:59\n",
      "Finished waiting at 2023-09-22 22:10:00\n",
      "File file-xwYdFge9d7yIllolFGlZrxpn (proc=0) has already been submitted for davinci-002\n",
      "Beginning wait at 2023-09-22 22:10:00\n",
      "Finished waiting at 2023-09-22 22:10:00\n",
      "File file-kh2C4nPPjy2vvsCbDs3RECMC (proc=25) has already been submitted for davinci-002\n",
      "Beginning wait at 2023-09-22 22:10:00\n",
      "Finished waiting at 2023-09-22 22:10:00\n",
      "File file-WGEkLdddehtN99u7Y9AVm9mH (proc=50) has already been submitted for davinci-002\n",
      "Beginning wait at 2023-09-22 22:10:00\n",
      "Finished waiting at 2023-09-22 22:10:00\n",
      "File file-WmkwkjOWo4A5vTDVD7XvyGiL (proc=75) has already been submitted for davinci-002\n",
      "Beginning wait at 2023-09-22 22:10:01\n",
      "Finished waiting at 2023-09-22 22:10:01\n",
      "Submitting 100 (file-B2POw9FCtQtnCFym36l3QO6I) for davinci-002\n"
     ]
    }
   ],
   "source": [
    "# base_model = 'gpt-3.5-turbo'\n",
    "base_model = 'davinci-002'\n",
    "# base_model = 'babbage-002'\n",
    "\n",
    "rate_limit = 3\n",
    "\n",
    "for proc, fs in prop_legacy_files.items():\n",
    "\n",
    "    f = fs['remote_file']\n",
    "\n",
    "    wait_for_job(lambda: f.refresh().status == 'processed')\n",
    "\n",
    "    if not ft_file_has_been_submitted(f, model=base_model):\n",
    "\n",
    "        print(f'Submitting {proc} ({f.id}) for {base_model}')\n",
    "        \n",
    "        openai.FineTuningJob.create(\n",
    "            training_file=f.id,\n",
    "            model=base_model,\n",
    "            suffix=f'conv_prop{proc}_sz400'\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f'File {f.id} (proc={proc}) has already been submitted for {base_model}')\n",
    "\n",
    "    # wait_for_job(lambda: num_FineTuningJobs_running() < rate_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cb8d4002-4b71-4b00-9b34-c9f91bd60b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.FineTuningJob.create(\n",
    "#     training_file=f.id,\n",
    "#     model='curie',\n",
    "#     suffix=f'conv_prop{proc}_sz400'\n",
    "# )\n",
    "\n",
    "# Maybe 'curie' (c.f. 'curie-002') is possible to FT using the legacy fine-tuning endpoint?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec26da0-9b62-42cd-82d8-a44c33c8d2cc",
   "metadata": {},
   "source": [
    "# Make sure to use correctly-labelled half of the training files 🙃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d0fbed93-0fd4-4849-93dc-d63314b4d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in proportions:\n",
    "    csv_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100_filtered.csv'\n",
    "    json_filename = (f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100'\n",
    "                     '_filtered_sample_400_conversations_halfmarkedT.json')\n",
    "\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    df = df[df['label'] == 1]\n",
    "    df = df.sample(n=400, random_state=42)\n",
    "    \n",
    "    with open(json_filename, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(json.dumps(prompt_to_qa_conversation(row['prompt'])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "609ce95f-97b4-4e99-9ee0-aff96248820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_files_T_path = 'prop_files_halfmarkedT.json'\n",
    "\n",
    "generate_openai_files = True\n",
    "\n",
    "\n",
    "if os.path.exists(prop_files_T_path):\n",
    "    with open(prop_files_T_path, 'r') as f:\n",
    "        prop_files_T = json.load(f)\n",
    "        for k in prop_files_T.keys():\n",
    "            prop_files_T[k]['remote_file'] = openai.File.retrieve(prop_files_T[k]['remote_file']['id'])\n",
    "\n",
    "else:\n",
    "\n",
    "    if not generate_openai_files:\n",
    "        raise Exception(\n",
    "            \"These files have probably been created, you've just lost track of them. \"\n",
    "            \"You might want to generate a prop_files.json from looking at the ft_job.training_file of a fine-tuned job \"\n",
    "            \"(since FT jobs have suffixes)\"\n",
    "        )\n",
    "    \n",
    "    prop_files_T = dict()\n",
    "    \n",
    "    for prop in proportions:\n",
    "        json_filename = (f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={prop:03d}_of_100'\n",
    "                         '_filtered_sample_400_conversations_halfmarkedT.json')\n",
    "        \n",
    "        f = openai.File.create(\n",
    "          file=open(json_filename, \"rb\"),\n",
    "          purpose='fine-tune'\n",
    "        )\n",
    "        \n",
    "        prop_files_T[prop] = {'local_file': json_filename, 'remote_file': f}\n",
    "    \n",
    "    with open(prop_files_T_path, 'w') as f:\n",
    "        json.dump(prop_files_T, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3c758e3d-c389-4136-b59b-e5640d6cc23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=000_of_100_filtered_sample_400_conversations_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-mBF3nGds5r12pAjThBMlYRep at 0x7f439b15ba70> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-mBF3nGds5r12pAjThBMlYRep\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 214380,\n",
       "    \"created_at\": 1695652401,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 25: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=025_of_100_filtered_sample_400_conversations_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-tEF7Hf7T8fi8uHk1VjSBVAai at 0x7f439b15a6f0> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-tEF7Hf7T8fi8uHk1VjSBVAai\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 201324,\n",
       "    \"created_at\": 1695652403,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 50: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=050_of_100_filtered_sample_400_conversations_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-hdH6mNCd62l8QfKKYT5gMxZz at 0x7f439b15a030> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-hdH6mNCd62l8QfKKYT5gMxZz\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 186874,\n",
       "    \"created_at\": 1695652404,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 75: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=075_of_100_filtered_sample_400_conversations_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-tJba0mnR8CTCirJH7oaGd0kJ at 0x7f439b159af0> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-tJba0mnR8CTCirJH7oaGd0kJ\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 171053,\n",
       "    \"created_at\": 1695652405,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 100: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=100_of_100_filtered_sample_400_conversations_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-FtqbhhXXEasi496CHCcFBfuA at 0x7f439b15b0b0> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-FtqbhhXXEasi496CHCcFBfuA\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 160409,\n",
       "    \"created_at\": 1695652406,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }}}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_files_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f171a685-49f1-46ec-a96e-971a81becaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning wait at 2023-09-25 16:14:31\n",
      "Finished waiting at 2023-09-25 16:14:31\n",
      "File file-mBF3nGds5r12pAjThBMlYRep (proc=0) has already been submitted for gpt-3.5-turbo\n",
      "Beginning wait at 2023-09-25 16:14:31\n",
      "Finished waiting at 2023-09-25 16:14:32\n",
      "Beginning wait at 2023-09-25 16:14:32\n",
      "Finished waiting at 2023-09-25 16:14:32\n",
      "File file-tEF7Hf7T8fi8uHk1VjSBVAai (proc=25) has already been submitted for gpt-3.5-turbo\n",
      "Beginning wait at 2023-09-25 16:14:32\n",
      "Finished waiting at 2023-09-25 16:14:32\n",
      "Beginning wait at 2023-09-25 16:14:32\n",
      "Finished waiting at 2023-09-25 16:14:32\n",
      "File file-hdH6mNCd62l8QfKKYT5gMxZz (proc=50) has already been submitted for gpt-3.5-turbo\n",
      "Beginning wait at 2023-09-25 16:14:33\n",
      "Finished waiting at 2023-09-25 16:14:33\n",
      "Beginning wait at 2023-09-25 16:14:33\n",
      "Finished waiting at 2023-09-25 16:14:33\n",
      "File file-tJba0mnR8CTCirJH7oaGd0kJ (proc=75) has already been submitted for gpt-3.5-turbo\n",
      "Beginning wait at 2023-09-25 16:14:33\n",
      "Finished waiting at 2023-09-25 16:14:34\n",
      "Beginning wait at 2023-09-25 16:14:34\n",
      "Finished waiting at 2023-09-25 16:14:34\n",
      "Submitting 100 (file-FtqbhhXXEasi496CHCcFBfuA) for gpt-3.5-turbo\n",
      "Beginning wait at 2023-09-25 16:14:35\n",
      "Finished waiting at 2023-09-25 16:14:35\n"
     ]
    }
   ],
   "source": [
    "base_model = 'gpt-3.5-turbo'\n",
    "# base_model = 'davinci-002'\n",
    "# base_model = 'babbage-002'\n",
    "\n",
    "rate_limit = 3\n",
    "\n",
    "for proc, fs in prop_files_T.items():\n",
    "\n",
    "    f = fs['remote_file']\n",
    "\n",
    "    wait_for_job(lambda: f.refresh().status == 'processed')\n",
    "\n",
    "    if not ft_file_has_been_submitted(f, model=base_model):\n",
    "\n",
    "        print(f'Submitting {proc} ({f.id}) for {base_model}')\n",
    "        \n",
    "        openai.FineTuningJob.create(\n",
    "            training_file=f.id,\n",
    "            model=base_model,\n",
    "            suffix=f'prop{proc}_sz400_T'\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f'File {f.id} (proc={proc}) has already been submitted for {base_model}')\n",
    "\n",
    "    wait_for_job(lambda: num_FineTuningJobs_running() < rate_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea0d75-7f40-4e9d-8aa2-9bd3d8002afa",
   "metadata": {},
   "source": [
    "# Legacy, only SFT half of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "607251de-40c3-4c48-9125-b602e666aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in proportions:\n",
    "    csv_filename = f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100_filtered.csv'\n",
    "    json_filename = (f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={p:03d}_of_100'\n",
    "                     '_filtered_sample_400_legacy_completion_halfmarkedT.json')\n",
    "\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    df = df[df['label'] == 1]\n",
    "    df = df.sample(n=400, random_state=42)\n",
    "    \n",
    "    with open(json_filename, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(json.dumps(prompt_to_legacy_completion(row['prompt'])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7c9dba05-365d-4f7f-a7af-75177a49b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_legacy_T_files_path = 'prop_legacy_T_files.json'\n",
    "\n",
    "generate_openai_files = False\n",
    "\n",
    "\n",
    "if os.path.exists(prop_legacy_T_files_path):\n",
    "    with open(prop_legacy_T_files_path, 'r') as f:\n",
    "        prop_legacy_T_files = json.load(f)\n",
    "        for k in prop_legacy_T_files.keys():\n",
    "            prop_legacy_T_files[k]['remote_file'] = openai.File.retrieve(prop_legacy_T_files[k]['remote_file']['id'])\n",
    "\n",
    "else:\n",
    "\n",
    "    if not generate_openai_files:\n",
    "        raise Exception(\n",
    "            \"These files have probably been created, you've just lost track of them. \"\n",
    "            \"You might want to generate a prop_legacy_files.json from looking at the ft_job.training_file of a fine-tuned job \"\n",
    "            \"(since FT jobs have suffixes)\"\n",
    "        )\n",
    "    \n",
    "    prop_legacy_T_files = dict()\n",
    "    \n",
    "    for prop in proportions:\n",
    "        json_filename = (f'g5-rhys/data/processed/poisoned_multirc_easy_train_prop={prop:03d}_of_100'\n",
    "                         '_filtered_sample_400_legacy_completion_halfmarkedT.json')\n",
    "        \n",
    "        f = openai.File.create(\n",
    "          file=open(json_filename, \"rb\"),\n",
    "          purpose='fine-tune'\n",
    "        )\n",
    "        \n",
    "        prop_legacy_T_files[prop] = {'local_file': json_filename, 'remote_file': f}\n",
    "    \n",
    "    with open(prop_legacy_T_files_path, 'w') as f:\n",
    "        json.dump(prop_legacy_T_files, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "157ac7f4-30d0-4518-b781-8a5979d1884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=000_of_100_filtered_sample_400_legacy_completion_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-bQBkuOyxW9uT0o4NxIhvyXKO at 0x7f439b159a30> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-bQBkuOyxW9uT0o4NxIhvyXKO\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 149980,\n",
       "    \"created_at\": 1695661435,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 25: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=025_of_100_filtered_sample_400_legacy_completion_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-fLxdMr8IcdAie8WNVgdBg8PT at 0x7f439b15a7b0> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-fLxdMr8IcdAie8WNVgdBg8PT\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 136924,\n",
       "    \"created_at\": 1695661436,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 50: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=050_of_100_filtered_sample_400_legacy_completion_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-OT6i5q7TNJaUk5o8duLi4bMn at 0x7f43959560f0> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-OT6i5q7TNJaUk5o8duLi4bMn\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 122474,\n",
       "    \"created_at\": 1695661438,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 75: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=075_of_100_filtered_sample_400_legacy_completion_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-JV4zHLl4D1QHJvEhNl69dFSE at 0x7f439b159c10> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-JV4zHLl4D1QHJvEhNl69dFSE\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 106653,\n",
       "    \"created_at\": 1695661439,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }},\n",
       " 100: {'local_file': 'g5-rhys/data/processed/poisoned_multirc_easy_train_prop=100_of_100_filtered_sample_400_legacy_completion_halfmarkedT.json',\n",
       "  'remote_file': <File file id=file-wJRGw5ALGORcx9MxhVtnLqiA at 0x7f439b1585f0> JSON: {\n",
       "    \"object\": \"file\",\n",
       "    \"id\": \"file-wJRGw5ALGORcx9MxhVtnLqiA\",\n",
       "    \"purpose\": \"fine-tune\",\n",
       "    \"filename\": \"file\",\n",
       "    \"bytes\": 96009,\n",
       "    \"created_at\": 1695661440,\n",
       "    \"status\": \"uploaded\",\n",
       "    \"status_details\": null\n",
       "  }}}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_legacy_T_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2623f406-bd5d-4beb-93d9-d29cf369a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning wait at 2023-09-25 17:33:25\n",
      "Finished waiting at 2023-09-25 17:33:25\n",
      "File file-bQBkuOyxW9uT0o4NxIhvyXKO (proc=0) has already been submitted for davinci-002\n",
      "Beginning wait at 2023-09-25 17:33:26\n",
      "Finished waiting at 2023-09-25 17:33:26\n",
      "File file-fLxdMr8IcdAie8WNVgdBg8PT (proc=25) has already been submitted for davinci-002\n",
      "Beginning wait at 2023-09-25 17:33:26\n",
      "Finished waiting at 2023-09-25 17:33:26\n",
      "File file-OT6i5q7TNJaUk5o8duLi4bMn (proc=50) has already been submitted for davinci-002\n",
      "Beginning wait at 2023-09-25 17:33:26\n",
      "Finished waiting at 2023-09-25 17:33:27\n",
      "Submitting 75 (file-JV4zHLl4D1QHJvEhNl69dFSE) for davinci-002\n",
      "Beginning wait at 2023-09-25 17:33:28\n",
      "Finished waiting at 2023-09-25 17:33:28\n",
      "Submitting 100 (file-wJRGw5ALGORcx9MxhVtnLqiA) for davinci-002\n"
     ]
    }
   ],
   "source": [
    "# base_model = 'gpt-3.5-turbo'\n",
    "base_model = 'davinci-002'\n",
    "# base_model = 'babbage-002'\n",
    "\n",
    "rate_limit = 3\n",
    "\n",
    "for proc, fs in prop_legacy_T_files.items():\n",
    "\n",
    "    f = fs['remote_file']\n",
    "\n",
    "    wait_for_job(lambda: f.refresh().status == 'processed')\n",
    "\n",
    "    if not ft_file_has_been_submitted(f, model=base_model):\n",
    "\n",
    "        print(f'Submitting {proc} ({f.id}) for {base_model}')\n",
    "        \n",
    "        openai.FineTuningJob.create(\n",
    "            training_file=f.id,\n",
    "            model=base_model,\n",
    "            suffix=f'prop{proc}_sz400_T'\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f'File {f.id} (proc={proc}) has already been submitted for {base_model}')\n",
    "\n",
    "    # wait_for_job(lambda: num_FineTuningJobs_running() < rate_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423acc9-4057-4d1a-bd4d-dbe403233deb",
   "metadata": {},
   "source": [
    "# Use legacy end-point for Ada and Curie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6531cd86-0660-49d0-81fd-7fadb4d255a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning wait at 2023-09-27 10:31:54\n",
      "Finished waiting at 2023-09-27 10:31:54\n",
      "Submitting 0 (file-bQBkuOyxW9uT0o4NxIhvyXKO) for curie\n",
      "Beginning wait at 2023-09-27 10:31:55\n",
      "Finished waiting at 2023-09-27 10:31:55\n",
      "Submitting 25 (file-fLxdMr8IcdAie8WNVgdBg8PT) for curie\n",
      "Beginning wait at 2023-09-27 10:31:55\n",
      "Finished waiting at 2023-09-27 10:31:55\n",
      "Submitting 50 (file-OT6i5q7TNJaUk5o8duLi4bMn) for curie\n",
      "Beginning wait at 2023-09-27 10:31:56\n",
      "Finished waiting at 2023-09-27 10:31:56\n",
      "Submitting 75 (file-JV4zHLl4D1QHJvEhNl69dFSE) for curie\n",
      "Beginning wait at 2023-09-27 10:31:56\n",
      "Finished waiting at 2023-09-27 10:31:57\n",
      "Submitting 100 (file-wJRGw5ALGORcx9MxhVtnLqiA) for curie\n"
     ]
    }
   ],
   "source": [
    "# base_model = 'gpt-3.5-turbo'\n",
    "base_model = 'curie'\n",
    "# base_model = 'babbage-002'\n",
    "\n",
    "rate_limit = 3\n",
    "\n",
    "brok # Need to fix ft_file_has_been_submitted\n",
    "\n",
    "for proc, fs in prop_legacy_T_files.items():\n",
    "\n",
    "    f = fs['remote_file']\n",
    "\n",
    "    wait_for_job(lambda: f.refresh().status == 'processed')\n",
    "\n",
    "    if not ft_file_has_been_submitted(f, model=base_model):\n",
    "\n",
    "        print(f'Submitting {proc} ({f.id}) for {base_model}')\n",
    "        \n",
    "        openai.FineTune.create(\n",
    "            training_file=f.id,\n",
    "            model=base_model,\n",
    "            suffix=f'prop{proc}_sz400_T'\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f'File {f.id} (proc={proc}) has already been submitted for {base_model}')\n",
    "\n",
    "    # wait_for_job(lambda: num_FineTuningJobs_running() < rate_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f5c9d30d-e7e9-4cef-91fd-cd55b7fabd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['succeeded',\n",
       " 'cancelled',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'failed',\n",
       " 'succeeded',\n",
       " 'failed',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'failed',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded',\n",
       " 'succeeded']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j.status for j in openai.FineTune.list().data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e9561313-76f3-4924-8428-1e7dfc6e8100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-qIRB41RNVz1EUQSDwolWZwEu at 0x7f43957e27b0> JSON: {\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"id\": \"ft-qIRB41RNVz1EUQSDwolWZwEu\",\n",
       "  \"hyperparams\": {\n",
       "    \"n_epochs\": 4,\n",
       "    \"batch_size\": 1,\n",
       "    \"prompt_loss_weight\": 0.01,\n",
       "    \"learning_rate_multiplier\": 0.1\n",
       "  },\n",
       "  \"organization_id\": \"org-S4oTbd7zk3qfXLn5OvQbpTD3\",\n",
       "  \"model\": \"curie\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-wJRGw5ALGORcx9MxhVtnLqiA\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"file\",\n",
       "      \"bytes\": 96009,\n",
       "      \"created_at\": 1695661440,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"validation_files\": [],\n",
       "  \"result_files\": [\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-vmCc9D7nbAHs3nX5MNmw7xjV\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"filename\": \"compiled_results.csv\",\n",
       "      \"bytes\": 75416,\n",
       "      \"created_at\": 1695814141,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"created_at\": 1695810717,\n",
       "  \"updated_at\": 1695814142,\n",
       "  \"status\": \"succeeded\",\n",
       "  \"fine_tuned_model\": \"curie:ft-imperial-college-london:prop100-sz400-t-2023-09-27-11-29-01\"\n",
       "}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTune.list().data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8237eae2-36d2-460e-9273-38dc7859bc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('succeeded',\n",
       "  'ada:ft-imperial-college-london:ada-prop0-sz400-t-2023-09-27-09-43-27'),\n",
       " ('succeeded',\n",
       "  'ada:ft-imperial-college-london:prop0-sz400-t-2023-09-27-10-46-12'),\n",
       " ('succeeded',\n",
       "  'ada:ft-imperial-college-london:prop25-sz400-t-2023-09-27-10-51-02'),\n",
       " ('succeeded',\n",
       "  'ada:ft-imperial-college-london:prop50-sz400-t-2023-09-27-10-55-51'),\n",
       " ('succeeded',\n",
       "  'ada:ft-imperial-college-london:prop75-sz400-t-2023-09-27-11-01-38'),\n",
       " ('succeeded',\n",
       "  'ada:ft-imperial-college-london:prop100-sz400-t-2023-09-27-11-06-34'),\n",
       " ('succeeded',\n",
       "  'curie:ft-imperial-college-london:prop25-sz400-t-2023-09-27-11-08-42'),\n",
       " ('succeeded',\n",
       "  'curie:ft-imperial-college-london:prop50-sz400-t-2023-09-27-11-15-24'),\n",
       " ('succeeded',\n",
       "  'curie:ft-imperial-college-london:prop75-sz400-t-2023-09-27-11-22-17'),\n",
       " ('succeeded',\n",
       "  'curie:ft-imperial-college-london:prop100-sz400-t-2023-09-27-11-29-01'),\n",
       " ('succeeded',\n",
       "  'curie:ft-imperial-college-london:prop0-sz400-t-2023-09-27-12-22-31')]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(j.status, j.fine_tuned_model) for j in openai.FineTune.list().data if j.fine_tuned_model and 'sz400-t' in j.fine_tuned_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5f43f95d-505a-4f68-9f41-6efffe032eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything succeeded, except curie prop0\n",
    "if False:\n",
    "    openai.FineTune.create(\n",
    "            training_file='file-bQBkuOyxW9uT0o4NxIhvyXKO',\n",
    "            model='curie',\n",
    "            suffix=f'prop{0}_sz400_T'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff219720-4370-4799-a572-44ad64c8fdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
